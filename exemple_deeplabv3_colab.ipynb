{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NailKhelifa/FewShotsLearning/blob/main/exemple_deeplabv3_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8pYWlF3AsKnw"
   },
   "source": [
    "**Notation:** \\\n",
    "N : batch size \\\n",
    "C : nb classes \\\n",
    "H : height \\\n",
    "W : width \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "F3fUysGPrdd0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gregoireyasmine-degobert/miniconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/gregoireyasmine-degobert/miniconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <E03EDA44-89AE-3115-9796-62BA9E0E2EDE> /Users/gregoireyasmine-degobert/miniconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <F75BB06B-2723-344D-99CE-9CB8BB94077A> /Users/gregoireyasmine-degobert/miniconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/Users/gregoireyasmine-degobert/miniconda3/lib/python3.11/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/gregoireyasmine-degobert/miniconda3/lib/python3.11/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
    "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8HKF1a_2NKi",
    "outputId": "95fa29ab-3152-4f68-92ec-d67b591fd491"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVLaz9jPrKGg"
   },
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h8VThil9qXTe",
    "outputId": "b0617ab4-2faa-4799-9103-adb03a7a5e49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "from pathlib import Path\n",
    "import cv2\n",
    "\n",
    "drive.mount('/content/drive')\n",
    "data_dir = Path(\"drive/MyDrive/Raidium - Challenge data 2022/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Pid2brCmttK5"
   },
   "outputs": [],
   "source": [
    "def load_dataset(dataset_dir):\n",
    "    dataset_list = []\n",
    "    for image_file in list(sorted(Path(dataset_dir).glob(\"*.png\"), key=lambda filename: int(filename.name.rstrip(\".png\")))):\n",
    "        dataset_list.append(cv2.imread(str(image_file), cv2.IMREAD_GRAYSCALE))\n",
    "    return np.stack(dataset_list, axis=0)\n",
    "\n",
    "data_train = load_dataset(data_dir / \"X_train\")\n",
    "data_test = load_dataset(data_dir / \"X_test\")\n",
    "\n",
    "labels_train = pd.read_csv(data_dir  / \"Y_train.csv\", index_col=0).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEDdUHC91PhC"
   },
   "source": [
    "Regardons le nombre de classes totales pour les labels, et le nombre de classes max par image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LFuPsDdK1Obw",
    "outputId": "f15ed402-8cc2-47af-bb3f-fef2b6bce4eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_classes = labels_train.max().max() + 1\n",
    "max_classes = np.max([len(np.unique(labels_train.iloc[k])) for k in range(len(labels_train))])\n",
    "tot_classes, max_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qk8Hc5Gi1vE3"
   },
   "source": [
    "Bien qu'il y aie 104 classes différentes dans les labels, on remarque qu'il n'y en a au maximum que 30 par image. On peut réduire la valeur des labels pour chaque image avec le code suivant (long) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NRjijqWMLCFQ",
    "outputId": "c30b697e-d873-4437-f4f3-9814f4cbd04c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-2bd1634149b9>:3: FutureWarning: Specifying the specific value to use for `na_sentinel` is deprecated and will be removed in a future version of pandas. Specify `use_na_sentinel=True` to use the sentinel value -1, and `use_na_sentinel=False` to encode NaN values.\n",
      "  labels, _ = pd.factorize(row, na_sentinel = 0)\n"
     ]
    }
   ],
   "source": [
    "def consecutive_values(row):\n",
    "    \"\"\"Modifie les valeurs de la ligne pour obtenir des entiers entre 0 et le nb de classes sur l'image tout en conservant les différences\"\"\"\n",
    "    labels, _ = pd.factorize(row, na_sentinel = 0)\n",
    "    return labels\n",
    "\n",
    "labels_train = labels_train.to_numpy()\n",
    "labels_trainr = np.array([consecutive_values(row) for row in labels_train])\n",
    "labels_trainr = pd.DataFrame(labels_trainr)\n",
    "tot_classes = labels_trainr.max().max() + 1\n",
    "\n",
    "assert tot_classes == max_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6UhQuHPtIg2"
   },
   "source": [
    "### Créer des datasets simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aUUwGruiqlRo",
    "outputId": "e8d23401-b7c4-4174-87e9-4ff97d082ccc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 1447.46it/s]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "for k in tqdm(range(len(labels_trainr))) :\n",
    "  labels.append(torch.tensor(np.array(labels_trainr.iloc[k]).reshape(512, 512)))\n",
    "\n",
    "y_train = torch.stack(labels[0:800])\n",
    "x_train = torch.tensor(data_train[0:800]).unsqueeze(1) # unsqueeze pour la dimension des channels de couleur (1 car greyscale)\n",
    "\n",
    "y_valid = torch.stack(labels[800:])\n",
    "x_valid = torch.tensor(data_train[800:]).unsqueeze(1)\n",
    "\n",
    "# A ce stade on peut supprimer les données qui ne servent plus pour libérer de la RAM\n",
    "del labels_train\n",
    "del labels_trainr\n",
    "del labels\n",
    "del data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yqyYUqoUzKQf"
   },
   "outputs": [],
   "source": [
    "class DataSet_with_transform(Dataset):\n",
    "    def __init__(self, x_dataset, y_dataset, transform=None):\n",
    "        self.x = x_dataset\n",
    "        self.y = y_dataset\n",
    "        assert len(self.x) == len(self.y), \"x and y should have same length\"\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.x[idx], self.y[idx]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return [x, y]\n",
    "\n",
    "# train_dataset = DataSet_with_transform(x_train, y_train)\n",
    "# valid_dataset = DataSet_with_transform(y_valid, x_valid)\n",
    "\n",
    "# un dataloader simple pour batcher le train dataset:\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size = 64, shuffle = True, pin_memory = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5aUNz-j6DEe"
   },
   "source": [
    "### Example de finetuning avec deeplabv3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAqC61_OCbVW"
   },
   "source": [
    "Commencons par charger le modèle et l'adapter à nos données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PVzhEYfK6CXy",
    "outputId": "28fd0f02-5a19-4cfa-fa62-828d32c90c99"
   },
   "outputs": [],
   "source": [
    "weights = DeepLabV3_ResNet50_Weights.DEFAULT # on commence par charger les weights\n",
    "model = deeplabv3_resnet50(weights=weights) # instanciation du modèle\n",
    "model.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) # on modifie la première couche pour prendre du greyscale\n",
    "resize = 520 # le resize adapté pour le modèle\n",
    "\n",
    "# On fait une fonction de preprocess pour resize et normalize\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(resize),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.225])])\n",
    "\n",
    "del weights\n",
    "# On fait une fonction de postprocess pour remettre faire correspondre l'output à la dimension des labels\n",
    "def postprocess(batch):\n",
    "  return F.interpolate(batch, 512, mode = 'nearest-exact')\n",
    "\n",
    "# print(model) # (pour regarder l'architecture si besoin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "vg69kDBUDEpi"
   },
   "outputs": [],
   "source": [
    "num_classes = 30 # le nombre de classes à détecter, 0 inclus\n",
    "# On va mettre max 12 classes pour réduire le temps d'éxécution/ la RAM\n",
    "in_channels = 256 # le nombre de canaux en entrée du classifier\n",
    "model.classifier[4] = DeepLabHead(in_channels, num_classes) # on change le classifier pour avoir le bon nombre de classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "p-pzXU2oHZyB"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dhtkc06tuFLt"
   },
   "source": [
    "On va créer un Dataset avec les images déja préprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "KCupm2-HyQ9Z"
   },
   "outputs": [],
   "source": [
    "train_dataset = DataSet_with_transform(x_train, y_train, transform = preprocess)\n",
    "valid_dataset = DataSet_with_transform(x_valid, y_valid, transform = preprocess)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 8, shuffle = True, pin_memory = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7tYUMjt5-88"
   },
   "source": [
    "#### La loss fonction qu'on va utiliser :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-UGKfZZSrCOf",
    "outputId": "52a62141-5c72-45e5-e2df-96e4287ddf43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7212, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "class MulticlassDiceLoss(nn.Module):\n",
    "    \"\"\" Reference: https://www.kaggle.com/code/bigironsphere/loss-function-library-keras-pytorch#Dice-Loss \"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, logits, targets, smooth=1e-6):\n",
    "        \"\"\"Computes the dice loss for all classes and provides an overall weighted loss.\"\"\"\n",
    "        probabilities = logits\n",
    "\n",
    "        targets_one_hot = torch.nn.functional.one_hot(targets.long(), num_classes=self.num_classes)\n",
    "        # Convert from NHWC to NCHW\n",
    "        targets_one_hot = targets_one_hot.permute(0, 3, 1, 2)\n",
    "\n",
    "        # Multiply one-hot encoded ground truth labels with the probabilities to get the\n",
    "        # prredicted probability for the actual class.\n",
    "        intersection = (targets_one_hot * probabilities).sum()\n",
    "\n",
    "        mod_a = intersection.sum()\n",
    "        mod_b = targets.numel()\n",
    "\n",
    "        dice_coefficient = 2. * intersection / (mod_a + mod_b + smooth)\n",
    "        dice_loss = -dice_coefficient.log()\n",
    "        return dice_loss\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  criterion = MulticlassDiceLoss(num_classes=30)\n",
    "  x, y = next(iter(train_dataloader))\n",
    "  x = x.to(device)\n",
    "  y = y.to(device)\n",
    "  logit = postprocess(model(x)['out'].softmax(dim = 1))\n",
    "print(criterion(logit, y))\n",
    "del x\n",
    "del y\n",
    "del logit\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QfihPSyGkdfR",
    "outputId": "c13e0ba6-0390-44aa-e054-1398f287cf4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Average Loss: 0.031249210285022855, Mean batch Time: 3.0026 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "model.train()\n",
    "num_epochs = 10\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.005)\n",
    "loss_over_epochs = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    batch_loss = []\n",
    "    epoch_start_time = time.time()  # Mesure du temps de l'époque\n",
    "    for x, y in train_dataloader:\n",
    "        start_time = time.time()\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = postprocess(model(x)['out'].softmax(dim=1))\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss.append(loss.item())\n",
    "\n",
    "        batch_time = time.time() - start_time\n",
    "        torch.cuda.empty_cache()\n",
    "    epoch_time = time.time() - epoch_start_time  # Calcul du temps écoulé pour l'époque\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {np.mean(batch_loss)}, Mean batch Time: {epoch_time/100:.4f} seconds')\n",
    "\n",
    "    loss_over_epochs.append(np.mean(batch_loss))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
