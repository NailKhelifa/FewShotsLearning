{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NailKhelifa/FewShotsLearning/blob/main/exemple_deeplabv3_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8pYWlF3AsKnw"
   },
   "source": [
    "**Notation:** \\\n",
    "N : batch size \\\n",
    "C : nb classes \\\n",
    "H : height \\\n",
    "W : width \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.9.0.80-cp37-abi3-macosx_10_16_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/gregoireyasmine-degobert/miniconda3/lib/python3.11/site-packages (from opencv-python) (1.26.3)\n",
      "Downloading opencv_python-4.9.0.80-cp37-abi3-macosx_10_16_x86_64.whl (55.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.9.0.80\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "F3fUysGPrdd0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gregoireyasmine-degobert/miniconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/gregoireyasmine-degobert/miniconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <E03EDA44-89AE-3115-9796-62BA9E0E2EDE> /Users/gregoireyasmine-degobert/miniconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <F75BB06B-2723-344D-99CE-9CB8BB94077A> /Users/gregoireyasmine-degobert/miniconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/Users/gregoireyasmine-degobert/miniconda3/lib/python3.11/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "/Users/gregoireyasmine-degobert/miniconda3/lib/python3.11/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50, DeepLabV3_ResNet50_Weights\n",
    "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import cv2\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e8HKF1a_2NKi",
    "outputId": "95fa29ab-3152-4f68-92ec-d67b591fd491"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n",
    "data_dir = os.getcwd() + '/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pVLaz9jPrKGg"
   },
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "Pid2brCmttK5"
   },
   "outputs": [],
   "source": [
    "def load_dataset(dataset_dir):\n",
    "    dataset_list = []\n",
    "    for image_file in list(sorted(Path(dataset_dir).glob(\"*.png\"), key=lambda filename: int(filename.name.rstrip(\".png\")))):\n",
    "        dataset_list.append(cv2.imread(str(image_file), cv2.IMREAD_GRAYSCALE))\n",
    "    return np.stack(dataset_list, axis=0)\n",
    "\n",
    "data_train = load_dataset(data_dir + \"/X_train\")\n",
    "data_test = load_dataset(data_dir + \"/X_test\")\n",
    "\n",
    "labels_train = pd.read_csv(data_dir + \"/Y_train.csv\", index_col=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = load_dataset(data_dir + \"/X_train\")\n",
    "data_test = load_dataset(data_dir + \"/X_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FEDdUHC91PhC"
   },
   "source": [
    "Regardons le nombre de classes totales pour les labels, et le nombre de classes max par image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LFuPsDdK1Obw",
    "outputId": "f15ed402-8cc2-47af-bb3f-fef2b6bce4eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106, 31)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_classes = labels_train.max().max() + 1\n",
    "max_classes = np.max([len(np.unique(labels_train.iloc[k])) for k in range(len(labels_train))])\n",
    "tot_classes, max_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qk8Hc5Gi1vE3"
   },
   "source": [
    "Bien qu'il y aie 104 classes différentes dans les labels, on remarque qu'il n'y en a au maximum que 30 par image. On peut réduire la valeur des labels pour chaque image avec le code suivant (long) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NRjijqWMLCFQ",
    "outputId": "c30b697e-d873-4437-f4f3-9814f4cbd04c"
   },
   "outputs": [],
   "source": [
    "def consecutive_values(row):\n",
    "    \"\"\"Modifie les valeurs de la ligne pour obtenir des entiers entre 0 et le nb de classes sur l'image tout en conservant les différences\"\"\"\n",
    "    l, _ = pd.factorize(row, sort=True)\n",
    "    return l\n",
    "\n",
    "labels_train = labels_train.to_numpy()\n",
    "labels_trainr = np.array([consecutive_values(row) for row in labels_train])\n",
    "labels_trainr = pd.DataFrame(labels_trainr)\n",
    "\n",
    "tot_classes = labels_trainr.max().max() + 1\n",
    "\n",
    "assert tot_classes == max_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i6UhQuHPtIg2"
   },
   "source": [
    "### Créer des datasets simples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aUUwGruiqlRo",
    "outputId": "e8d23401-b7c4-4174-87e9-4ff97d082ccc"
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "for k in range(len(labels_trainr)) :\n",
    "    labels.append(torch.tensor(np.array(labels_trainr.iloc[k]).reshape(512, 512)))\n",
    "\n",
    "\n",
    "y_train = torch.stack(labels[0:300])\n",
    "x_train = torch.tensor(data_train[0:300]).unsqueeze(1)  # unsqueeze pour la dimension des channels de couleur (1 car greyscale)\n",
    "\n",
    "y_valid = torch.stack(labels[300:400])\n",
    "x_valid = torch.tensor(data_train[300:400]).unsqueeze(1)\n",
    "\n",
    "x_test = torch.tensor(data_test).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.852734\n",
       "1       0.861603\n",
       "2       0.771923\n",
       "3       0.785191\n",
       "4       0.832382\n",
       "          ...   \n",
       "1995    1.000000\n",
       "1996    1.000000\n",
       "1997    1.000000\n",
       "1998    1.000000\n",
       "1999    1.000000\n",
       "Length: 2000, dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(labels_trainr == 0).sum(axis = 1)/(512**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<NegBackward0 object at 0x12c366b90>\n"
     ]
    }
   ],
   "source": [
    "label = y_train[0:5].float()\n",
    "label.requires_grad = True\n",
    "random_output = torch.tensor(np.random.random((5, 31, 512, 512)), requires_grad=True).softmax(1)\n",
    "\n",
    "class MulticlassDiceLoss(nn.Module):\n",
    "    \"\"\" Reference: https://www.kaggle.com/code/bigironsphere/loss-function-library-keras-pytorch#Dice-Loss \"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, logits, targets, smooth=1e-6, ignore_index=0):\n",
    "        \"\"\"Computes the dice loss for all classes and provides an overall weighted loss.\"\"\"\n",
    "        probabilities = logits\n",
    "\n",
    "        targets_one_hot = torch.nn.functional.one_hot(targets.long(), num_classes=self.num_classes)\n",
    "        # Convert from NHWC to NCHW\n",
    "        targets_one_hot = targets_one_hot.permute(0, 3, 1, 2)\n",
    "\n",
    "        # Multiply one-hot encoded ground truth labels with the probabilities to get the\n",
    "        # prredicted probability for the actual class.\n",
    "        intersection = (targets_one_hot[:, ignore_index] * probabilities[:, ignore_index]).sum() \\\n",
    "            + (targets_one_hot[:, ignore_index+1:] * probabilities[:, ignore_index+1:]).sum()\n",
    "        n = (targets != 0).sum()\n",
    "\n",
    "        dice_coefficient = 2. * intersection / (intersection + n + smooth)\n",
    "        dice_loss = -dice_coefficient.log()\n",
    "        return dice_loss\n",
    "\n",
    "loss = MulticlassDiceLoss(num_classes = 31)\n",
    "\n",
    "l = loss(random_output, label)\n",
    "print(l.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MulticlassDiceLoss(nn.Module):\n",
    "    \"\"\" Reference: https://www.kaggle.com/code/bigironsphere/loss-function-library-keras-pytorch#Dice-Loss \"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, logits, targets, smooth=1e-6, ignore_index=0):\n",
    "        \"\"\"Computes the dice loss for all classes and provides an overall weighted loss.\"\"\"\n",
    "        probabilities = logits\n",
    "\n",
    "        targets_one_hot = torch.nn.functional.one_hot(targets.long(), num_classes=self.num_classes)\n",
    "        # Convert from NHWC to NCHW\n",
    "        targets_one_hot = targets_one_hot.permute(0, 3, 1, 2)\n",
    "\n",
    "        # Multiply one-hot encoded ground truth labels with the probabilities to get the\n",
    "        # prredicted probability for the actual class.\n",
    "        intersection = (targets_one_hot[:, ignore_index] * probabilities[:, ignore_index]).sum() \\\n",
    "            + (targets_one_hot[:, ignore_index+1:] * probabilities[:, ignore_index+1:]).sum()\n",
    "        print(intersection)\n",
    "        mod_a = intersection.sum()\n",
    "        mod_b = targets.numel()\n",
    "\n",
    "        dice_coefficient = 2. * intersection / (mod_a + mod_b + smooth)\n",
    "        dice_loss = -dice_coefficient.log()\n",
    "        return dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yqyYUqoUzKQf"
   },
   "outputs": [],
   "source": [
    "class DataSet_with_transform(Dataset):\n",
    "    def __init__(self, x_dataset, y_dataset, transform=None):\n",
    "        self.x = x_dataset\n",
    "        self.y = y_dataset\n",
    "        assert len(self.x) == len(self.y), \"x and y should have same length\"\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.x[idx], self.y[idx]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        return [x, y]\n",
    "\n",
    "# train_dataset = DataSet_with_transform(x_train, y_train)\n",
    "# valid_dataset = DataSet_with_transform(y_valid, x_valid)\n",
    "\n",
    "# un dataloader simple pour batcher le train dataset:\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size = 64, shuffle = True, pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B5aUNz-j6DEe"
   },
   "source": [
    "### Example de finetuning avec deeplabv3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAqC61_OCbVW"
   },
   "source": [
    "Commencons par charger le modèle et l'adapter à nos données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PVzhEYfK6CXy",
    "outputId": "28fd0f02-5a19-4cfa-fa62-828d32c90c99"
   },
   "outputs": [],
   "source": [
    "weights = DeepLabV3_ResNet50_Weights.DEFAULT # on commence par charger les weights\n",
    "model = deeplabv3_resnet50(weights=weights) # instanciation du modèle\n",
    "model.backbone.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) # on modifie la première couche pour prendre du greyscale\n",
    "resize = 520 # le resize adapté pour le modèle\n",
    "\n",
    "# On fait une fonction de preprocess pour resize et normalize\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(resize),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.225])])\n",
    "\n",
    "del weights\n",
    "# On fait une fonction de postprocess pour remettre faire correspondre l'output à la dimension des labels\n",
    "def postprocess(batch):\n",
    "  return F.interpolate(batch, 512, mode = 'nearest-exact')\n",
    "\n",
    "# print(model) # (pour regarder l'architecture si besoin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "vg69kDBUDEpi"
   },
   "outputs": [],
   "source": [
    "num_classes = 30 # le nombre de classes à détecter, 0 inclus\n",
    "# On va mettre max 12 classes pour réduire le temps d'éxécution/ la RAM\n",
    "in_channels = 256 # le nombre de canaux en entrée du classifier\n",
    "model.classifier[4] = DeepLabHead(in_channels, num_classes) # on change le classifier pour avoir le bon nombre de classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "p-pzXU2oHZyB"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dhtkc06tuFLt"
   },
   "source": [
    "On va créer un Dataset avec les images déja préprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "KCupm2-HyQ9Z"
   },
   "outputs": [],
   "source": [
    "train_dataset = DataSet_with_transform(x_train, y_train, transform = preprocess)\n",
    "valid_dataset = DataSet_with_transform(x_valid, y_valid, transform = preprocess)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = 8, shuffle = True, pin_memory = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L7tYUMjt5-88"
   },
   "source": [
    "#### La loss fonction qu'on va utiliser :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-UGKfZZSrCOf",
    "outputId": "52a62141-5c72-45e5-e2df-96e4287ddf43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7212, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "class MulticlassDiceLoss(nn.Module):\n",
    "    \"\"\" Reference: https://www.kaggle.com/code/bigironsphere/loss-function-library-keras-pytorch#Dice-Loss \"\"\"\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, logits, targets, smooth=1e-6):\n",
    "        \"\"\"Computes the dice loss for all classes and provides an overall weighted loss.\"\"\"\n",
    "        probabilities = logits\n",
    "\n",
    "        targets_one_hot = torch.nn.functional.one_hot(targets.long(), num_classes=self.num_classes)\n",
    "        # Convert from NHWC to NCHW\n",
    "        targets_one_hot = targets_one_hot.permute(0, 3, 1, 2)\n",
    "\n",
    "        # Multiply one-hot encoded ground truth labels with the probabilities to get the\n",
    "        # prredicted probability for the actual class.\n",
    "        intersection = (targets_one_hot * probabilities).sum()\n",
    "\n",
    "        mod_a = intersection.sum()\n",
    "        mod_b = targets.numel()\n",
    "\n",
    "        dice_coefficient = 2. * intersection / (mod_a + mod_b + smooth)\n",
    "        dice_loss = -dice_coefficient.log()\n",
    "        return dice_loss\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "  criterion = MulticlassDiceLoss(num_classes=30)\n",
    "  x, y = next(iter(train_dataloader))\n",
    "  x = x.to(device)\n",
    "  y = y.to(device)\n",
    "  logit = postprocess(model(x)['out'].softmax(dim = 1))\n",
    "print(criterion(logit, y))\n",
    "del x\n",
    "del y\n",
    "del logit\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QfihPSyGkdfR",
    "outputId": "c13e0ba6-0390-44aa-e054-1398f287cf4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Average Loss: 0.031249210285022855, Mean batch Time: 3.0026 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "model.train()\n",
    "num_epochs = 10\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.005)\n",
    "loss_over_epochs = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    batch_loss = []\n",
    "    epoch_start_time = time.time()  # Mesure du temps de l'époque\n",
    "    for x, y in train_dataloader:\n",
    "        start_time = time.time()\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = postprocess(model(x)['out'].softmax(dim=1))\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        batch_loss.append(loss.item())\n",
    "\n",
    "        batch_time = time.time() - start_time\n",
    "        torch.cuda.empty_cache()\n",
    "    epoch_time = time.time() - epoch_start_time  # Calcul du temps écoulé pour l'époque\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {np.mean(batch_loss)}, Mean batch Time: {epoch_time/100:.4f} seconds')\n",
    "\n",
    "    loss_over_epochs.append(np.mean(batch_loss))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
